In the course of our work, diverse corpora have been used. 
First, general tagging methods are developed employing the Szeged Corpus \cite{Csendes2004}.
Further on, such algorithms have been tested on Old and Middle Hungarian \cite{Novak2013} texts as well.
Next, methods for speech transcripts are analyzed on the \acrshort{hukilc} corpus\cite{Matyus2014}.
Besides, two corpora have been created manually from electronic health records in order to develop and evaluate algorithms for the clinical domain.
Depending on the task nature, texts were split into training, development and test sets.

Concerning methods used, most of our work result in hybrid solutions.
On one hand, we build on symbolic morphological analyzers and rule-based (sometimes pattern matching) components. 
On the other hand, stochastic and machine learning algorithms are heavily utilized as well.

Morphological analyzers play central role in this work, since their usage is inevitable for morphologically complex languages.
In most of the cases we employed (adapted versions \cite{Novak2013,Orosz2013} of) Humor \cite{Novak2003,Proszeky1994} but the \acrshort{ma} of \texttt{magyarlanc} \cite{zsibrata2013magyarlanc} has been used as well.

As regards machine learning, tagging experiments are based on hidden Markov models \cite{Rabiner1989,Samuelsson1993}. 
Our approach builds on two well known tools which are Brant's TnT \cite{Brants2000} and HunPos \cite{Halacsy2007} from Hal√°csy et al. 
Besides, other well known methods such as $n$-gram modeling, suffix-tries and interpolation techniques are utilized as well.
Further on, the proposed combination method utilizes instance based learning \cite{Aha1991} implemented in the Weka toolkit \cite{Hall2009}.

Next, text segmentation models utilize unsupervised techniques as well.
A collocation extractions measure of Dunning \cite{dunning1993accurate} is used for detecting sentence boundaries.
In fact, we base on the study of Kiss and Strunk \cite{kiss2006unsupervised} employing scaling factors for the $\log\lambda$ collocation measure.

Finally, the evaluation of algorithms are carried out employing standard metrics.
Performance of taggers are measured using precision counting correct annotation of tokens and sentences.
However, when the corpus investigated contained a considerable amount of punctuation marks they were not involved in the computation.
Improvement of taggers are usually examined calculating relative error reduction rate. 
Further on, numeric values are compared computing mean relative error \cite{Witten2011} ratio and Pearson's correlation coefficient \cite{Witten2011}.
Finally, simple classification scenarios are evaluated with standard metrics.
Therefore, precision, recall and F is computed for each class, while overall accuracy values are provided as well.