In the course of our work, diverse corpora were used. 
First, the Szeged Corpus \cite{Csendes2004} was employed for developing and evaluating general tagging methods.
Further on, these algorithms were tested on Old and Middle Hungarian \cite{Novak2013} texts as well.
Next, methods for speech transcripts were analyzed on the \acrshort{hukilc} corpus \cite{Matyus2014}.

Beside existing ones, two new corpora were created manually from electronic health records.
These texts enabled us to design algorithms for the clinical domain.
Concerning their usage, texts were usually split into training, development and test sets.

As regards methods used, most of our work resulted in hybrid solutions.
On the one hand, we built on symbolic morphological analyzers and rule-based (pattern matching) components. 
On the other hand, stochastic and machine learning algorithms were heavily utilized as well.

Morphological analyzers played a central role in our study, since their usage is inevitable for morphologically complex languages.
In most of the cases we employed (adapted versions \cite{Novak2013,NovakOMK,Orosz2013}) of Humor ~\cite{Proszeky1994,Novak2003,Proszeky2005} but the \acrshort{ma} of \texttt{magyarlanc} \cite{zsibrata2013magyarlanc} was used as well.

As regards machine learning algorithms, tagging experiments were based on hidden Markov models \cite{Rabiner1989,Samuelsson1993}. 
Our approach built on two well-known tools which are Brant's TnT \cite{Brants2000} and HunPos \cite{Halacsy2007} from Hal√°csy et al. 
Besides, other common methods such as $n$-gram modeling, suffix-tries and general interpolation techniques were utilized as well.
Further on, the proposed combination scheme applied instance based learning \cite{Aha1991} implemented in the Weka toolkit \cite{Hall2009}.

Beside supervised learning, unsupervised techniques were employed as well.
Identification of sentences was performed using the collocation extractions measure of Dunning \cite{dunning1993accurate}.
In fact, we based on the study of Kiss and Strunk \cite{kiss2006unsupervised}, which employs scaling factors for the $\log\lambda$ ratio.

The effectiveness of algorithms was measured calculating standard metrics.
The performance of taggers were computed with precision as counting correct annotations of tokens and sentences.
However, if the corpus investigated contained a considerable amount of punctuation marks, they were not involved in the computation.
For significance tests, we used the paired Wilcoxon signed rank test as implemented in the SciPy toolkit \cite{scipy}.
Next, the improvement of taggers was examined calculating relative error rate reduction. 

Simple classification scenarios were evaluated computing precision, recall and F-score for each class.
Furthermore, overall accuracy values were provided as well.
Finally, numeric scores were compared with mean relative error \cite{Witten2011} and Pearson's correlation coefficient \cite{Witten2011}.