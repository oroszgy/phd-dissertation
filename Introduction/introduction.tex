\section{Preprocessing in natural language technology}

% mi a nyelvtech
% 2*2-es felosztás
% mik a legfontosabb feladatok
% általában hogyan épül fel egy feldolgozási lánc
% error propagaton

% mit nevezek preprocessingnek
% mi a text segmentation

Natural language technology is present in our everyday life helping interactions between humans and computers.
As such, it is a field of computer science and linguistics, which involves understanding and generating of human (natural) languages.
%Beside this categorization, another one can be created considering the target of tasks: applications can handle either text or speech.
Concerning text processing, which is a major part of language technology, several structural levels can be identified:
\begin{description}
\item[Text segmentation:] basic units of texts are separated, thus token  and sentence boundaries are recognized (referred as tokenization \gls{sbd}).
\item[Morphological parsing:] structural units of words are identified (morphological analysis), then tokens are unambiguously classified by their morpho-syntactic behavior (\acrlong{pos} tagging).
\item[Syntactic parsing:] sentences are broken down into building blocks regarding their form, function or syntactic relation to each other.
\item[Semantic analysis] methods deal with the \emph{meaning} of texts.
\end{description}

Practical applications often build parsing chains, pipelining such components one after another. 
%While several modules are not available for numerous languages, t
Two preprocessing steps are indispensable for most of the cases.
Since words and sentences are the basic units of text mining applications, segmentation must be performed first.
Beside this, lemmata and \gls{pos} labels of words are also necessary components of such systems, thus morphological parsing should be carried out next.

Moving on, such pipelined architectures may easily result in erroneous output, since error propagation is often a notable phenomenon. 
Obviously, the more accurate preprocessing modules are employed, the better analyses are yielded. Therefore, the high precision of such methods is crucial.

\section{A solved problem?}


% hogyan szokták megoldani a tokenizálást/SBD-t => bár megoldott, de nem mindig
% hogyan szokták megoldani a PoS taggelést => megoldott, de nem mindig
	% mi a morf. egyért. 
	% lem

Text segmentation is composed of two parts: tokenization and sentence boundary identification. 
The first one brakes texts into meaningful elements (called tokens) usually utilizing pattern matching methods.
Next, sentence boundaries are often recognized by applying linguistic rules or using machine learning algorithms.
In most of the cases, these solutions are fine-tuned for a specific task, hence resulting in accurate tools, i.e. the problem is considered to be solved.
%In addition, such systems usually remain robust amongst domains, hence 
%In that way the problem is considered to be solved.
However, these algorithms are often language and domain specific, thus numerous scenarios exist (such as the case of noisy texts) on which current approaches fail.

Having identified the tokens themselves, the \gls{pos} tags of words are assigned.
%Next, \acrshort{pos} tagging is another well-researched field of \gls{nlp}, as there are diverse methods for numerous languages. 
In practice, these solutions mostly build on data-driven algorithms requiring large amount of training data.
As a result, such approaches are restricted by the corpus they model.
%Therefore, transferring their knowledge to a new domain is often complicated without a satisfactory amount of annotated data.
Further on, most of the tagging algorithms target English first, thus ignoring serious problems caused by languages with rich morphology.
For instance, agglutinative languages (such as Hungarian) have rich inflection systems.
Words are formed joining affixes to the lemma, thus affecting their morpho-syntactic behavior.
In that way, such languages need much larger (morpho-syntactic) tagsets compared to English. 
Furthermore, lemmatization of words cannot be carried out using simple suffix-stripping methods.
This means, disambiguating among part-of-speech labels becomes insufficient, full morphological tagging algorithms are required that assign complete morpho-syntactic tags and compute lemmata as well.

All in all, language technology needs preprocessing methods which handle morphologically rich languages efficiently 
and perform well on less-resourced scenarios at the same time.

\section{Aims of the study}

The aim of this study is twofold. 
Firstly, morphological tagging algorithms are investigated which can handle agglutinative languages and is applicable for domain adaptation scenarios effectively. 
Secondly, methods suitable for a less-resourced domain are examined.

First, we were interested in \textbf{how existing methods can be applied for the full morphological tagging of agglutinative languages yet remaining suitable for domain adaptation tasks}. 
Chapter \ref{chap:tagging} considers many aspects of this question. 
Section \ref{sec:purepos} focuses on the full disambiguation problem, in particular on the question of \textbf{how one can create a morphological tagging architecture that is accurate on agglutinative languages and also flexible enough to be used in rule-based domain adaptation tasks}.
Further on,  this section also investigates \textbf{how a method can be created which computes roots of words (either seen or unseen previously by the algorithm) effectively}. 
On the one hand, an efficient lemmatizer was developed which integrates a \gls{ma} and employs several stochastic models as well. % to
On the other hand, an efficient tagging tool (PurePos) is designed that is customizable for diverse domains.
Our system was tested on a general Hungarian corpus showing its state-of-the-art accuracy. 
In addition, hybrid components of the tool were also examined through an annotation task showing their conduciveness.


Following this, Section \ref{sec:combination} examines \textbf{how one can improve full morphological taggers through system combination to raise the overall annotation quality}.
We developed an architecture for combining morphological taggers for agglutinative languages, which improves tagging quality significantly.


Beside tagging methods, their applications also played a central role in this study.
We were interested in \textbf{creating a tagger tool for speech transcripts which can help linguists in their research}.
%We were interested in \textbf{how PurePos can help linguistic research in speech}.
Chapter \ref{chap:mlu} presents adaptation methods resulting in the first morphological tagging chain for spoken Hungarian.
Following this, an application of this system is described which estimates morpho-syntactic complexity of speech transcripts of children automatically.

The third part of the dissertation (Chapter \ref{chap:clin}) deals with problems of Hungarian electronic health records.
In particular, Section \ref{sec:clin_segm} investigates \textbf{how one can develop a text segmentation algorithm which can handle imperfect sentence and word boundaries in Hungarian medical texts}. 
Our contribution in this field is twofold. 
First, it was shown that all the available tools fail on segmenting such texts.
Next, an accurate methodology was proposed identifying sentence and token boundaries precisely.

Following this, Section \ref{sec:clin_tag} looks into the questions \textbf{what the main pitfalls of morphological taggers are which target noisy clinical texts} and \textbf{how PurePos can be adapted for tagging medical texts properly}.
This part introduces a detailed error analysis of the tool showing that abbreviations and \gls{oov} words cause most of the errors.
In addition, domain-specific adaptation techniques are presented improving the annotation quality significantly.

%After presenting, Chapter \ref{chap:sum} sums up the contributions of the study. 
%In that way, theses of the dissertation is presented highlighting the main results and pointing to the author's related publications.


\section{Methods of investigation}
\input{Summary_en/methods}
