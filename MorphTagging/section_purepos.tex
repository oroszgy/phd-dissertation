First, existing tagging methods are surveyed. 
Next, the new hybrid morphological tagging algorithm is described detailing its components and architecture. 
Finally, the presented tool is evaluated through several experiments showing its superior performance.

\subsection{Background}

First of all, we overview how morphological disambiguator systems are typically built up. 
Since there are just a few tools performing full morphological tagging, we also review PoS tagging attempts for morphologically rich languages. 
In addition, previous Hungarian tagging approaches are introduced as well, hence Hungarian plays an important role in our experiments.

\subsubsection{Full morphological tagging}

There has been insufficient discussion about full morphological tagging in recent studies of natural language technology. 
The reason behind this is that most of the attempts concentrate on morphologically not very rich languages (such as English), where PoS tagging is generally sufficient and the ambiguity of the lemmatization task is negligible. 
Furthermore, there are studies even for inflectional languages ignoring lemmatization (such as~\cite{Hajic1998a,Tufis1998,Silfverberg2011}), which follow English approaches. 

Nevertheless, studies published on full morphological tagging can be grouped depending on their relationship to lemmatization.

\begin{enumerate}
  \item First of all, numerous researchers propose a two stage model, where the first stage is responsible for finding full morphosyntactic tags, while the second one is for identifying lemmata for \emph{(word, tag)} pairs. 
  For instance, Erjavec and Dzeroski decompose the problem~\cite{Erjavec2004} by utilizing a trigram  tagger first, then applying a decision list lemmatizer. \label{part:general-lemmatization}
  Further on, Agic et al. combine~\cite{Agic2013} an HMM-based tagger with a data-driven rule-based lemmatizer~\cite{Jongejan}. 
  Even though such combinations could have error propagation issues, they usually result in well-established accuracy.
  \item Another feasible approach is to treat the tagging task as a disambiguation problem. 
  Such methods use morphological analyzers to generate annotations candidates, then use disambiguation methods selecting the correct analyses.
  This architecture is typical e.g. for Turkish (cf.~\cite{Sak2007,Hakkani-Tur2002}).
  %, but similar studies are also published for Czech (such as~\cite{valamelyikHajic}) as well. 
  A drawback of this approach is that the disambiguation components depend heavily on the language-dependent analyzer used.
  \item Finally, the problem can be also handled as a unified tagging task.
  A recent study presents the morfette system~\cite{Chrupaa2008}.
  It employs a joint architecture for tagging words with their tags and lemmata considering lemmatization as a labeling problem.
  Thus a lemma class is a transformation sequence describing string modifications from the surface form to the root.
  This tool utilizes the maxent framework employing separate models for each of the subtasks but using a joint beam search decoder.
  A similar method was presented by Laki and Orosz~\cite{Laki2013} recently.
  Their system (HuLaPos) merges PoS labels with lemmata transformation sequences to a unified tag, which is then learned by the Moses statistical machine translation framework.
  Therefore HuLaPos can \emph{translate} sentences to sequences of labels.
  Such joint approaches are usually language independent, however, they can either be slow or inaccurate due to increased search space.
\end{enumerate}

Considering lemmatization (as in \ref{part:general-lemmatization}), the task can be easily accomplished by using rules or lemma dictionaries, however their creation is time-consuming.
A baseline method is to select the most frequent lemmata for each \emph{(word, tag)} relying on the training data (as in~\cite{zsibrata2013magyarlanc}). 
Despite its simplicity this method usually result in a low precision system.
Further on, employing advanced ML algorithms is also a viable approach.
E.g. Plisson et al. apply Ripple Down Rule induction algorithms~\cite{Plisson2004} for learning suffix transformation.
However, their attempt ignores the dependency between tags and lemmata.
Next, Jongejan and Dalianis generate decision lists (cf. CST method~\cite{Jongejan}) for handling morphological changes in pre-, in- and suffixes.
Their approach is optimized for inflecting languages by exploring complex changes in word forms.  

\subsubsection{Morphosyntactic tagging of morphologically rich languages}

We describe how well-known PoS tagging methods are applied for morphologically rich languages focusing on issues yielded by the complexity of the morphology.
We review only machine learning models by investigating their performance and methods for managing
\begin{enumerate}
  \item increased number of out-of-vocabulary word forms and
  \item the large complexity of the tagset. 
\end{enumerate}

While numerous attempts have been published for tagging Polish recently~\cite{Piasecki2006,Piasecki2007,Acedanski2010,Radziszewski2013},  performance of such tools presented are below the average.
Most of these solutions use morphological analyzers to get possible morphosyntactic tag candidates, thus reducing the search space of the decoder.
Further on, tiered tagging is a widely utilized technique~\cite{Radziszewski2013}.
This method resolves complex tags by computing its parts one after another.
Considering ML algorithms used, the range of applications is wide.
Beside an adaptation of Brill’s tagger~\cite{Acedanski2010}, C4.5 decision trees~\cite{Piasecki2007}, memory-based learning principle~\cite{Radziszewski2011} and CRF models are employed~\cite{Radziszewski2013} as well. 

The first successful attempt to analyze Czech was published by Hajič and Hladká~\cite{Hajic1998a} basing on a discriminative model.
Their approach uses a morphological analyzer and builds on individual prediction models for ambiguity classes.
Actually, the best results for Czech are obtained using the combination of numerous systems~\cite{Hajic2007}.
In their solution, three different stochastic taggers (HMM, Maximum Entropy and Averaged perceptron) and symbolic components are utilized as well.
A MA computes the possible analyses, while the rule-based disambiguator tool removes agrammatical tag sequences. 

The flexible architecture of the Stanford tagger allows the integration of various morphological features enabling its usage for morphologically rich languages.
An example is~\cite{Georgiev2012} by Georgiev et al. using a morphological lexicon and an extended feature set to analyze Bulgarian.
Beside discriminative methods, applications of trigram tagging methods have been demonstrated (for example Croatian~\cite{Agic2013}, Slovenian~\cite{Agic2013} and Icelandic~\cite{Loftsson2007}) to be effective as well.
In contrast with former studies, accurate HMM based systems usually rely on large morphological lexicons and decent unknown word guessing algorithms.

Considering agglutinative languages with a rich inflectional system, the usage of finite-state methods is indispensable.
Silferberg and Lindén introduce an HMM-based tagger for Finnish~\cite{Silfverberg2011} relying on a weighted finite-state model.
As regards Turkish, Daybelge and Cicelki describe a system~\cite{Daybelge2007} employing also a finite-state rule-based method.
Most taggers for agglutinative languages use hybrid architectures incorporating morphological analyzers into stochastic learning methods.
Examples are the perceptron based application of Sak et al.~\cite{Sak2007} and the trigram tagging approach of Dilek et al.~\cite{Hakkani-Tur2002}.

To summarize, effective methods for morphologically complex languages rely on either a discriminative or a generative model.
Such taggers generally use morphological lexicons or analyzers to handle the large vocabulary of the target language.
Further on, tagging of unknown words is a crucial problem being managed by either guessing modules or rich morphological features. 

\subsubsection{The case of Hungarian}

As regards Hungarian PoS tagging, the first attempt was performed by Megyesi~\cite{Megyesi1998} adapting Brill’s transformation based method~\cite{Brill1992}.
Since she did not use any morphological lexicon, her approach resulted in moderate success.
Similarly, Horváth et al. investigated \cite{Horvath1999} only pure machine learning algorithms (such as C4.5 or instance based learning) thus resulting in low accuracy systems.
Three years later, the first promising approach was presented by Oravecz and Dienes~\cite{Oravecz2002a} utilizing TnT with a weighted finite-state lexical model.
In 2006, Halácsy et al. investigated an augmented maxent model~\cite{Halacsy2006} in combination with language specific morphological features and a MA.
In that study, their best result was achieved by combining the latter model with a trigram based tagger.
Later, they created the HunPos system~\cite{Halacsy2007} which reimplements and extends TnT~\cite{Brants2000}.
Their results (with a morphological lexicon) has been shown to be as efficient as the one of Oravecz and Dienes.
Next, Kuba et al. investigated boosting and bagging techniques for transformation based learning.
Although they managed to reduce the error rate of the baseline tagger, their results lag behind previous approaches.
Recently, Zsibrita et al. published \texttt{magyarlanc}~\cite{zsibrata2013magyarlanc}, a natural language processing chain for Hungarian.
They adapted the Stanford PoS tagger by filtering its suggestions with a morphological analyzer. 

Concerning full tagging involving lemmatization, there are only two methods available for Hungarian.
Although magyarlanc is designed for Hungarian, its lemmatization subsystem is rather simple.
The tool assigns the most common lemmata (depending on the morphosyntactic label) to known words, and employs a rule based unknown word guesser.
Moving on, HuLaPos is applied to Hungarian as well~\cite{Laki2013}, but its performance shown to be dissatisfactory in numerous scenarios. 

This study introduces an accurate morphological tagging method.
We utilize trigram-based PoS tagging, since it has superior performance for Hungarian and other agglutinative languages.
The presented tool is adapted for morphologically rich languages and resource-scarce scenarios.
It involves a lemmatization component differing from previous ones yet being competitive with them.
Furthermore, our approach is shown to have state-of-the-art performance for Hungarian while utilizing a language independent hybrid architecture.
In addition, short training time is also guaranteed due to the simple HMM model used.



\subsection{The new model for full morphological tagging}

The architecture of PurePos (cf. Figure \ref{fig:purepos-arch}) is built up on a multi-phase model. 
The data flow starts from a MA providing word analyses as \emph{(lemma, tag)} pairs. 
Next, a trigram model is used to select morphosyntactic labels for words. 
Then, lemmatization is carried out using both statistical and linguistic components. 

\begin{figure}[ht]
  \centering
  \includegraphics[width=1\textwidth]{MorphTagging/architecture.png} 
  \caption{The architecture of the proposed method}
  \label{fig:purepos-arch}
\end{figure}

We present the design and components of our algorithm that make the morphological tagging effective. First, underlying statistical models are introduced, then we show how symbolic algorithms can be effectively incorporated in our method. 

\subsubsection{The PoS tagging model}

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.5\textwidth]{MorphTagging/pos_arch.png} 
  \caption{The process of part-of-speech tagging in the proposed system}
  \label{fig:pos_arch}
\end{figure}

PurePos builds on methods introduced in TnT, allowing it to be fast, simple and effective at the same time. 
Similarly to its predecessors, our model (see Figure \ref{fig:pos_arch}) selects the best $t_1 \dots t_m$ label sequence for $w_1 \dots w_n$ words by calculating:
\begin{equation}
\argmax_{t_1^m} \prod_{i=1}^m P(t_i | t_{i-1}^{i-n}) P(w_i|t_{i-1}^{i-n})
\end{equation}
for $w_1 \dots w_n$ words. 

Its contextual model is computed with $n$-gram probability estimates (cf. Equation \ref{eq:purepos-contextual}) derived from maximum likelihood estimation (see Equation \ref{eq:purepos-contextual2}). Uni-, bi- and trigram estimates are combined with deleted interpolation calculating $\lambda_k$ weights as suggested by Brants \cite{Brants2000}. Even though the order of the model is usually set to 3, it is adjustable in practice. 


\begin{equation}\label{eq:purepos-contextual}
P(t_i | t_{i-1}^{i-n}) = \sum_{k=0}^{n-1} \lambda_k \hat{P}(t_i|t_{i-1}^{i-k})
\end{equation}

\begin{equation}\label{eq:purepos-contextual2}
\hat{P}(t_i|t_{i-1}^{i-k}) = \frac{c(t^{i-k}_i)}{c(t_{i-1}^{i-k})} (k>0) \\
\hat{P}(t_i) = \frac{c(t_i)}{N} (k=0)
\end{equation}

Next, the lexical model of our method \eqref{eq:purepos-lexical} is composed of two components. 
The first one is for tokens previously seen in the training data, while the second guesses labels for unknown words. 
In fact, each subsystem is doubled (as it is in the original study \cite{Brants2000}) maintaining separate models for uppercase and lowercase words. 

Handling of previously seen words is carried out approximating $P(w_i | t_{i}^{i-n})$: 
\begin{equation} \label{eq:purepos-lexical}
P(w_i | t_{i}^{i-n}) = \sum_{k=0}^{n-1} \lambda_k \hat{P}(w_i|t_{i}^{i-k})
\end{equation}

\label{sec:purepos-guesser}
We employ MLE for $\hat{P}(w_i|t_{i}^{i-k})$ and apply deleted interpolation for the $\lambda_k$ weights. 
Similarly to the contextual model, $k$ is usually set to 2 in applications.

As regards tagging of unknown words, we use -- in accordance with Brants -- the distribution of rare\footnote{Rare words are considered to be those that occur less than 10 times in the training data.}
 tokens’ tags for estimating their PoS label. Since suffixes are strong predictors for tags in agglutinative languages, we use their ($\{s_{n-l+1} \dots s_n\}$) $l$ long combined frequencies for the guessing process:

\begin{align}
 P(t|s_{n-l+1}, \dots, l_n) 
 = \frac{ \hat{P}(t|s_{n-l+1}, \dots, s_n) + \theta_i \hat{P}(t|s_{n-l}, \dots, s_n)}{1+\theta_i}
\end{align}

In doing so, $\theta_i$ parameters are calculated with successive abstraction, while MLE is utilized  for $\hat{P}(t|\{s_{n-l+1}, \dots, s_n)$. 

Concerning decoding, beam search is utilized, since it can yield multiple tagging sequences at the same time. 
In that way, the tool is able to produce tagging scores of sentences \eqref{eq:purepos-score} allowing us to incorporate linguistic rules building on partly disambiguated word sequences. 

\begin{equation}\label{eq:purepos-score} %%TODO: ez történik, kell ez ide?
Score(w_1^m,t_1^m) = \log \prod_{i=1}^m P(w_i|t_i,t_{i-1})P(t_i|t_{i-1},t_{i-2})P(l_i|t_i,w_i)
\end{equation}

\subsubsection{The lemmatization model}

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.8\textwidth]{MorphTagging/lemma_arch.png} %TODO: javítani az ábrán
  \caption{The data flow of the lemmatization component}
  \label{fig:lemma-arch}
\end{figure}

Lemmatization is performed in two steps (cf. Figure \ref{fig:lemma-arch}). 
First, candidates are generated for \emph{(word, morphosyntactic tag)} pairs. 
If morphological analyses are available for the word, their lemmata are used as candidates, otherwise suffix-based guessing is carried out. 
For this, the guesser (described in Section \ref{sec:purepos-guesser}) has been extended to represent lemma transformations as well. 
In doing so, combined labels represent both the morphosyntactic tag and suffix-transformations for lemmata (for an example see Table \ref{tab:lemma-example}).


\begin{table}[ht]
\centering
\caption{Examples for the combined representation of the tag and lemma}
\label{tab:lemma-example}
\begin{tabular}{l | l l}
   \textbf{Word} &  \emph{házam} `my houses’ &  \emph{baglyot} `owl’ \\
   \textbf{Tag} &  \textsc{n.1}s\textsc{pos} &  \textsc{n.acc} \\
   \textbf{Lemma} &  \emph{ház} `house’ &  \emph{bagoly} `owl’ \\
   \textbf{Transformation} & -2+$\varnothing$ &  -4+\emph{oly} \\
   \textbf{Combined label} & (\textsc{n.1}s\textsc{pos}, -2,--) &  (\textsc{n.acc}, -4, \emph{oly}) \\
\end{tabular}
\end{table}


As for picking right lemmata, we utilize the conditional probability model
\begin{equation}\label{lemma-max}
\argmax_l P(l|t,w)
\end{equation}

computing the most probable lemma for the given token and part-of-speech tag. 
Probability estimation in \eqref{lemma-max} is carried out in a twofold way. On the one hand, a unigram lemma model ($\hat{P}(l)$) calculates conditional probabilities using relative frequency estimates. On the other hand, reformulation of the core of \eqref{lemma-max} yields another approximation method.


\begin{equation}\label{lemma-guesser}
P(l|t,w) = \frac{P(l,t|w)}{P(t|w)}
\end{equation}

Substituting this formula for the Equation \ref{lemma-max}, $P(t|w)$ becomes a constant which can be omitted. 
In that way, we can estimate $P(l,t|w)$ using the lemma guesser. Finally, models are aggregated employing log-linear interpolation: 

%TODO: P és P_kalap-okat átnézni
\begin{equation}\label{lemma-interpolated}
P(l|w,t) = P(l)^{\lambda_1} P(l,t|w)^{\lambda_2}
\end{equation}

\begin{algorithm*}[h]
\begin{algorithmic}[1]
    \ForAll{(word, tag, lemma)} 
        \State candidates $\gets$ generateLemmaCandidates(word, tag)
        \State maxUnigramProb $\gets$ getMaxProb(candidates, word, tag, unigramModel)
        \State maxSuffixProb $\gets$ getMaxProb(candidates, word, tag, suffixModel)
        \State actUnigramProb $\gets$ getProb(word, tag, lemma, unigramModel)
        \State actSuffixProb $\gets$ getProb(word, tag, lemma, suffixModel)
        \State unigramProbDistance $\gets$ maxUnigramProb $-$ actUnigramProb
        \State suffixProbDistance $\gets$ maxSuffixProb $-$ actSuffixProb
        \If {unigramProbDistance $>$ suffixProbDistance}
            \State $\lambda_{2} \gets$ $\lambda_{2}$ $+$ unigramProbDistance $-$ suffixProbDistance
        \Else%If{unigramProbDistance $<$ suffixProbDistance}
            \State $\lambda_{1} \gets$ $\lambda_{1}$ $+$ suffixProbDistance $-$ unigramProbDistance
        \EndIf
    \EndFor
    \State normalize$( \lambda_{1}, \lambda_{2} )$
  \end{algorithmic}
  \caption{Calculating parameters of the linear interpolated lemmatization model}
\label{lemma-interpolation-algorithm}
\end{algorithm*}

The idea of computing $\lambda_{1,2}$ parameters is similar to that seen for the PoS $n$-gram models. 
However, instead of using positive weights, negative penalty scores are stored for the worst performing model.  
It is calculated iterating over words of the training data (cf. Algorithm \ref{lemma-interpolation-algorithm}):
\begin{enumerate}
  \item first, both components return the best lemma assumed for each \emph{(word, tag)} pair, 
  \item then they compute probability estimates for the gold standard lemma,
  \item next, (absolute) error rates of the models are calculated ,
  \item finally, the worst model’s weight is decreased.
\end{enumerate}
After these steps, interpolation parameters are normalized.


\subsubsection{Hybridization}

Although the framework proposed builds on an existing PoS tagging algorithm, it is extended with a new lemmatization model and is modified to fit agglutinative languages such as Hungarian. 
Hybridization steps are listed below showing differences between PurePos and its predecessors.

\begin{description}
  \item[Morphological analyzer] \hfill \\
  First of all, a morphological analyzer is utilized throughout the whole process estimating probability scores only for valid\footnote{Valid analyses for a word are those which are proposed by the MA.} tags and lemmata.
  \item[Linguistic rules] \hfill \\
  Next, the proposed architecture allows rule-based components to modify the analyses of the MA. In that way, bad candidates can be filtered out. Furthermore, local lexical probability scores can be also given to PurePos, which are then used as context dependent distribution functions. 
  \item[Unseen tags] \hfill \\ 
  In contrast to TnT or HunPos, our system is able to handle unseen tags\footnote{Morphosyntactic labels which are not seen in the training data.} properly. On the one hand, if a token has only one analysis being unseen, that one gets selected with 1 lexical probability. Further on, estimation of forthcoming tags are performed using a lower level (unigram) model in this case. On the other hand, the system is able to calculate lexical and contextual scores for any tag previously not seen. This can be performed mapping latter tags to a previously seen ones using regular expressions.\footnote{For a complete example see Section \ref{sec:oldhungarian}.}
  \item[\emph{k}-best output] Finally, our method decodes tags using beam search. In doing so, one can generate partly disambiguated sentences being apt for linguistic post-processing. Further on, this facility allows the usage of advanced machine learning techniques resulting in more accurate parsing algorithms.
\end{description}


\subsection{Experiments}

%TODO: ezt a részt átézni
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Tagging general Hungarian}

First, PurePos is evaluated on Hungarian using the Szeged Corpus\footnote{Version 2.3 is utilized in our experiments, since the MA employed is only compatible with this corpus variation.}~\cite{Csendes2004} (SZC). 
This corpus contains general texts from seven genres being annotated with detailed MSD morphosyntactic tags~\cite{} and lemmata. %TODO: multext east
In addition, we used a variant of the same corpus tagged with the analyses of the Humor MA. These texts were split in 8:2 ratio for training and testing (as in Table \ref{tab:szeged-corpus}). 

\begin{table}[ht]
\centering
\caption{Dimensions of the corpora used}
\begin{tabular}{l r r r r}
  \hline
  & \multicolumn{2}{c}{MSD tagset} & \multicolumn{2}{c}{Humor tagset} \\
  &  Training set &  Test set &  Training set &  Test set  \\
  \hline
  Tokens &  1 232 384 &  254 880 &  980 225 &  214 123 \\
  Sentences &  68 321 &  13 778 &  56 792 &  14 198 \\
  Distinct tags &  1 032 &  716 &  983 &  656 \\
  \hline
\end{tabular}
\label{tab:szeged-corpus}
\end{table}

As a morphological analyzer is an integral part of our method, we tested the tool with two analyzers. 
The first setting utilizes the MSD tagged corpus and an analyzer extracted from \texttt{magyarlanc}, while the second one applies Humor with the transcribed corpus.

Evaluation is carried out measuring the overall precision of full annotations (i.e \emph{(morphosyntactic tag, lemma)} pairs). 
Further on, sentence-based accuracies are also provided in some cases. 
The latter metric is computed considering a sentence to be correct only when all of its tokens are properly tagged. 

Further on, morphological tagging tools available for Hungarian were also evaluated on these corpora. 
Firstly, \texttt{magyarlanc}, HuLaPos and morfette\footnote{Version 3.5 is used.} are compared with PurePos.  
Next, combination of lemmatization and PoS tagging tools are investigated. 
Such two-phase architectures have been shown to be prosperous (e.g.~\cite{Agic2013,Erjavec2004}) for several scenarios, therefore successful modules being commonly applied are involved in out experiments. 
Concerning PoS taggers, we use
\begin{itemize}
  \item the trigram tagging method of HunPos,
  \item averaged perceptron learning and
  \item the maximum entropy framework of the OpenNLP~\cite{Baldridge2002} toolkit.
\end{itemize}

As regards lemmatization tools, CST and a baseline method are employed. 
The latter one returns the root  candidate for a \emph{(word, tag) }pair being the most frequent in the training data. Beside these components, tag dictionaries have been prepared for HunPos. 
(For this, morphological analyzer tools are fed with the 100 000 most frequent words of Hungarian\footnote{Frequencies are calculated relying on the results of the Szószablya project~\cite{Halacsy2004}.}.) %TODO: ez tuti az?

\begin{table}[ht]
 \centering
 \caption{Morphological tagging result on the Szeged Corpus (annotated with MSD labels)}
\begin{tabular}{l r r r}
  \hline
  \textbf{Precision} &  \textbf{PoS tag} &  \textbf{Full annotation} &  \textbf{Sentence} \\
  \hline
  magyarlanc &  96.50\% &  95.72\% &  54.52\% \\
  Morfette &  96.94\% &  92.24\% &  38.18\% \\
  HuLaPos &   &   &   \\
  PurePos &  \textbf{96.99\%} &  \textbf{96.27\%} &  \textbf{58.06\%} \\
  HunPos + BL &  96.71\% &  92.65\% &  36.06\% \\
  HunPos + CST &  96.71\% &  91.19\% &  35.31\% \\
  Maxent + BL &  95.63\% &  92.21\% &  34.82\% \\
  Maxent + CST &  95.63\% &  90.14\% &  29.70\% \\
  Perceptron + BL &  95.19\% &  91.16\% &  29.42\% \\
  Perceptron + CST &  95.19\% &  89.78\% &  27.91\% \\
  \hline
\end{tabular}
\label{tab:morphtag-orig}
\end{table}


\begin{table}[ht]
 \centering
 \caption{Morphological tagging result on the transcribed Szeged Corpus (annotated with Humor labels)}
\begin{tabular}{l r r r}
  \hline
  \textbf{Precision} &  \textbf{PoS tag} &  \textbf{Token} &  \textbf{Sentence} \\
  \hline
  Morfette &  97.60\% &  94.73\% &  51.58\% \\
  HuLaPos &   &   &   \\
  PurePos &  \textbf{98.65\%} &  \textbf{98.58\%} &  \textbf{81.78\%} \\
  HunPos + BL &  97.41\% &  89.93\% &  32.07\% \\
  HunPos + CST &  97.41\% &  94.69\% &  52.40\% \\
  Maxent + BL &  94.81\% &  88.82\% &  28.19\% \\
  Maxent + CST &  94.81\% &  92.33\% &  40.10\% \\
  Perceptron + BL &  95.97\% &  88.85\% &  29.11\% \\
  Perceptron + CST &  95.97\% &  93.32\% &  45.13\% \\
  \hline
\end{tabular}
\label{tab:morphtag-humor}
\end{table}


First of all, there are notable discrepancies of the results on the two datasets. These can be mostly explained by the different annotation scheme they use:
\begin{itemize}
  \item First, the original corpus contains foreign and misspelled words being tagged with a uniform \textsc{x} tag. Due to the various syntactic behavior of such words, their labels can be hardly estimated using their context or their suffix.
  \item Further on, date expressions and several named entities are tagged with a single MSD code resulting in lemmata composed of more than one word. (An example is \emph{Golden Eye-oztunk} `we visited the Golden Eye’ being lemmatized as \emph{Golden Eye-ozik} `to visit the Golden Eye’.) 
  Such phenomena could be hard to handle for lemmatizers.
\end{itemize}

These effects together decreased the effectiveness of MSD-based taggers considerably. 
In contrast, the Humor-tagged corpus is free of such words, thus allowing taggers to achieve better precision scores.

Results in Tables \ref{tab:morphtag-orig} and \ref{tab:morphtag-humor} show that PurePos is the most accurate tool for Hungarian. 
First, it is very effective on PoS tagging thanks to the morphological analyzers used. 
Next, comparison of full annotation scores reveals that the new lemmatization algorithm significantly outperforms others. 
Full tagging accuracies of systems using CST lag behind the top results, while the performance measures of morfette and HuLaPos are significantly worse than that of PurePos.  
It has been also found that other two-stage taggers are far behind state-of-the-art results. 
Even though, the PoS accuracy of HunPos is close to the best ones, both of the standalone lemmatizers degrade the overall performance. 
This is due to the fact that the baseline method could have difficulties with unknown words, while CST was originally designed for inflectional languages. 
As regards the MSD-tagged corpus, magyarlanc yields first-class results with a precision of 95.72\%. 
However, its language specific components inhibit its application on other corpora. Finally, sentence based accuracies on the Humor-tagged corpus reveals that most of the tools result in erroneously tagged sentences in more than half of the cases, while the same number for PurePos is less than 20\%.



\subsubsection{Resource-scarce settings}

In this part, we show that our method, in contrast to others (cf. Section \ref{})\footnote{Unfortunately, we could not measure the performance of \texttt{magyarlanc}, since the current release of the tool cannot be trained.}, can be used effectively when just a small amount of annotated corpora is available. 
For this, we draw learning curves of systems employed in the previous experiment\footnote{Magyarlanc could not be involved in these experiments, since we were unable to train it.}. 
They are evaluated on the same datasets, while the training dataset is limited to only 2000, 4000, 6000, 8000 and 10000 sentences. %TODO: ellentmondás a token<->sent mennyiségek között: 5 vagy 6 adatpont

\begin{figure}[H]
  \centering
  \includegraphics[width=1\textwidth]{MorphTagging/msd_token.png} 
  \caption{Learning curves (regarding token accuracy) of full morphological taggers on the Szeged Corpus (using MSD labels)}
  \label{fig:msd-token}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=1\textwidth]{MorphTagging/humor_token.png}
  \caption{Learning curves (regarding token accuracy) of full morphological taggers on the Szeged Corpus (using Humor labels)}
  \label{fig:humor-token}
\end{figure}

Figures \ref{fig:msd-token} and \ref{fig:humor-token} present the morphological tagging accuracies of the systems depending on the number of tokens in the training corpus. 
These results are in accordance with conclusions of previous experiments of this study. 
In addition, our numbers confirm the effectiveness of the hybrid approach in cases when the amount of training data is limited.  

\begin{figure}[H]
  \centering
  \includegraphics[width=1\textwidth]{MorphTagging/msd_sent.png} 
  \caption{Learning curves (regarding sentence accuracy) of full morphological taggers on the Szeged Corpus (using MSD labels)}
  \label{fig:msd-sent}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=1\textwidth]{MorphTagging/humor_sent.png}
  \caption{Learning curves (regarding sentence accuracy) of full morphological taggers on the Szeged Corpus (using Humor labels)}
  \label{fig:humor-sent}
\end{figure}

If we compare (cf. Figures \ref{fig:msd-sent} and \ref{fig:humor-sent}) full sentence precisions, the differences between taggers are much more emphasized. 
For example having only 1000 sentences for training (with MSD tags), the proposed algorithm results in 38.7\% sentence precision compared to the second best of 14.67\%.

All in all, the architecture of PurePos allows producing accurate annotations when the amount  of training data is limited. 
Furthermore, its lemmatization method outperforms all other systems available for Hungarian.


\subsubsection{The case of Middle- Old-Hungarian}
\label{sec:oldhungarian}

Next, we present a tagging task showing the effectiveness of all the hybrid components of PurePos. 
In a project~\cite{Novak2013} aiming at the creation of an annotated corpus of Middle Hungarian texts, an adapted version of the Hungarian HuMor morphological analyzer was used. 
This tool was originally made to annotate contemporary Hungarian, but the grammar and lexicon were modified to handle morphological constructions existed in Middle Hungarian but have since disappeared from the language. 
In the experiments described here, we used a manually checked disambiguated portion of this corpus. The data was labeled using a rich variant of the HuMor tagset having cardinality over a thousand.

\begin{table}[ht]
\centering
\caption{Characteristics of the used corpus}\label{tab:oldhun-corpus}
\begin{tabular}{l r r r}
\hline
& Training & Dev. & Test \\
\hline
Documents & 140 & 20 & 30 \\
Clauses & 12355 & 2731 & 2484 \\
Tokens & 59926 & 12656 &  11763\\
\hline
\end{tabular}
\end{table}

We split the corpus into three parts (see Table \ref{tab:oldhun-corpus}). 
The tagger was trained on the biggest one, hybridization and adaptation methods were developed on a separate development subcorpus, while final evaluation was done on the test set.
We used again precision as an evaluation metric, but unambiguous punctuation tokens were \emph{not} taken into account (in contrast to how taggers are evaluated in general). 
They are ignored because the corpus contains a relatively large amount of punctuation markers which would distort the comparison.
Methods were evaluated in a twofold way: full morphological disambiguation accuracies were calculated for tokens and they were also computed to obtain clause-level precision values.

We used the enhanced trigram-based algorithm derived from HunPos and implemented in PurePos (PP) as a baseline PoS tagger. 
Further on, its enhancement relying on the HuMor analyzer (PPM) was also evaluated. As regards lemmatization, the simple unigram-based (BL) method (cf. Section \ref{sec:purepos-guesser}) was compared to the proposed one. 

\begin{table}[ht]
\centering
\caption{Baseline disambiguation accuracies on the development set}\label{tab:oldhun-baselines}
\begin{tabular}{l r r r}
\hline
 & Tokens & Clauses \\
\hline
% PP+BL & 93.20\% & 88.99\% & 55.58\% \\
PP+BL  & 88.99\% & 55.58\% \\
% PP+SL & 93.20\% & 89.01\% & 51.78\% \\
% PPM+BL & 97.77\% & 97.22\% & 84.85\% \\
PPM+BL  & 97.22\% & 84.85\% \\
% PPM+SL & 97.77\% & 97.50\% & 85.98\% \\
PP + CL & 92.14\% & 65.40\% \\
PPM + CL & 97.58\% & 86.48\% \\
\hline
\end{tabular}
\end{table}



First of all, me investigate the impact of the MA and the new lemmatization method. 
Performance of systems are presented in Table \ref{tab:oldhun-baselines}. 
It was found that the usage of a morphological component is indispensable. 
Comparing the baseline lemmatization with the combined method (CL) shows that the new the proposed algorithm yields a significant error rate reduction compared to the baseline. 
This improvement is even more notable on the development set when a dedicated morphological analyzer is not used (28.42\%).

We present further experiments in the next exhausting hybrid facilities of PurePos yielding a more accurate tagger. To that end, the development set was utilized to analyze common error types and to develop hypotheses.


\paragraph{Mapping of tags}

In contrast to other Hungarian annotation projects, the tag set of the historical corpus distinguishes verb forms that have a verbal prefix from those that do not, because this is a distinction important for researchers interested in syntax.\footnote{Hungarian verbal prefixes or particles behave similarly to separable verbal prefixes in most Germanic languages: they usually form a single orthographic word with the verb they modify, however, they are separated in certain syntactic constructions.} 
This practically doubles the number of verb tags\footnote{320 different verb tags occur in the corpus excluding verb prefix vs. no verb prefix distinction. This is just a fraction of the theoretically possible tags.}, which results in data sparseness problems for the tagger. 
In case of a never encountered tag having a verbal prefix marking, one can calculate probability estimates for that label by mapping it to one without a verbal prefix. 
This solution is viable, since the distribution of prefixed and non-prefixed verbs largely overlap. 
Applying this enhancement (TM), we could increase the accuracy of the system on the development set.

\paragraph{Preprocessing}

Another point of improvement is to filter analyses of Humor (FI). 
Exploiting the development set, a preprocessing script was set up which has five simple rules. 
Three of them catches the tagging of frequent phrases such as \emph{az a} `that' in which \emph{az} must be a pronoun. 
Further on two domain specific lexicons were employed to correct the erroneous annotation of proper names that coincide with frequent common nouns or adjectives. 
Using these correction rules the overall performance on the development set was further raised to 97.84\% token accuracy.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\paragraph{$k$-best output}
The $k$-best output of the tagger can either be used as a representation to apply upstream grammatical filters to or as candidates for alternative input to higher levels of processing. 
Five-best output for our test corpus has yielded an upper limit for attainable clause accuracy of 94.32\% (on the development set). 
While it is not directly comparable with the ones above, this feature could e.g. be used by syntactic parsers.

Measuring improvements on the test set, we validate their performance (see Table \ref{tab:oldhun-test}). 
Similarly to the development set, using the $5$-best output sequence of the tagger provide us much more golden annotations. 
These are available for 92.30\% of the clauses and for 98.66\% of the tokens.

\begin{table}[ht]
\centering
\caption{Disambiguation accuracies of the hybrid tool on the test set}
\label{tab:oldhun-test}
\begin{tabular}{l r r r}
\hline
 & Full & Clauses  \\
\hline
Baseline  & 89.47\% & 55.07\% \\
PurePos  & 96.48\% & 80.95\% \\
+TM  & 96.51\% & 81.17\% \\
+FI  & 96.60\% & 81.55\% \\
+ all  & 96.63\% & 81.77\% \\
+ all with \emph{k}-best  & 98.66 \% & 92.30\% \\
\hline
\end{tabular}
\end{table}
 

All in all, we have shown that one can further increase the tagging accuracy by employing hybrid facilities of PurePos. 
Rules has been employed to preprocess analyses candidates while unseen tags could be successfully mapped to previously seen ones. 
Finally, we have shown that $k$-best candidates contain significantly more golden annotations.



The $k$-best output of the tagger can either be used as a representation to apply upstream grammatical filters to or as candidates for alternative input to higher levels of processing.
Five-best output for our test corpus has yielded an upper limit for attainable clause accuracy of 94.32\%.
While it is not directly comparable with the ones above, this feature could be successfully used also in self-training or in tagger combination schemes.

Applying the given hybridization steps to the test set, we can validate the performance improvements (see results in Table \ref{tab:oldhun-test}).
Furthermore, using $k$-best output from the tagger, 92.30\% of clauses and 98.66\% of the tokens have the golden annotation among the top 5 output in the test set. 


