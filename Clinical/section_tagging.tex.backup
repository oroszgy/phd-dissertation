While morphological tagging of general texts is a well-known task and considered to be solved, medical texts pose new challenges to researchers. In addition, English has been the main target of many studies investigating the biomedical domain up to the present time. Therefore there are just a few tagging approaches for medical texts of non- English data. Moreover, agglutinative languages and particularly Hungarian are neglected.
Therefore this study investigate the tagging of Clinical Hungarian. In doing so, we present the adaptation of existing methods resulting an accurate tagger.

This section is structured as follows. Related studies are described first. Then, a corpus of clinical notes is presented, which has been created for developing and evaluating tagging algorithms. In Section \ref{sec:baseline}, we present a baseline morphological disambiguation chain and a detailed error analysis. Finally, domain adaptation enhancements are introduced and evaluated on the test corpus.

\subsection{Background}
\label{sec:biomed_tag}

Processing of biomedical texts has an extensive literature, since numerous resources are accessible for English. On the contrary, much less manually corpora of clinical texts are available. Further on, most of the work in this field has been done for English, while only a few attempts have been published for morphologically rich languages (e. g. \cite{oleynik2009performance,rost2008lessons}).

A common approach for biomedical PoS tagging is to employ supervised learning. However, these methods use manually annotated texts requiring labor-intense human work. Considering training material used for tagging biomedical texts, domain-specific corpora are used either alone \cite{pakhomov2006developing,savova2010mayo,Smith2006} or in conjunction with a (sub)corpus of general English \cite{coden2005domain,ferraro2013improving,miller2007building} as training data. 
While employing texts only from the target domain yields acceptable performance \cite{pakhomov2006developing,savova2010mayo,Smith2006}, 
several experiments have shown that accuracy further increases with incorporating annotated sentences from the general domain as well \cite{barrett2011token,coden2005domain}. 
A general observation is that the more data is used from the reference domain, the higher accuracy can be achieved (e. g. \cite{pestian2004development}). 
On the contrary, Hahn and Wermter argue for training learners only on general corpora \cite{hahn2004tagging} (for German). 
Besides, there are studies on selecting training data (e. g. \cite{liu2007heuristic}) to increase accuracy. 
What is more, there are methods (such as \cite{choi2012fast}) which learn from several domains in a parallel fashion delaying the model selection decision to the decoding process. 

Utilizing domain-specific lexicons is another way of adapting taggers, as they can improve tagging performance significantly \cite{coden2005domain,ruch2000minimal}. 
Some of these studies extend existing PoS dictionaries \cite{divita2006dtagger}, while others build new specific ones \cite{Smith2006}. 
In brief, all of the experiments employing such resources yield significantly reduced error rates. 

Concerning tagging algorithms, researchers tend to prefer already existing applications. One of the most popular tool is the OpenNLP toolkit\footnote{\url{http://opennlp.apache.org/}}, which is e.g. the basis of the cTakes system \cite{savova2010mayo}.
Further on, Brill’s method \cite{Brill1992} and TnT \cite{Brants2000} are widely used (e.g. \cite{hahn2004tagging,savova2010mayo,pestian2004development}) as well. 
Besides, other HMM-based solutions have been shown to perform well \cite{barrett2011token,coden2005domain,divita2006dtagger,hahn2004tagging,pakhomov2006developing,rost2008lessons,ruch2000minimal} on such texts. 

Moving on, number of experiments have revealed \cite{ferraro2013improving,ruch2000minimal,Smith2006} that domain-specific OOV words are behind the reduced performance of taggers. Therefore, successful methods employ either guessing algorithms \cite{barrett2011token,divita2006dtagger,rost2008lessons,ruch2000minimal,Smith2006} or broad-coverage lexicons (as detailed above). Beyond supervised algorithms, other approaches were also shown to be effective: Miller et al. \cite{miller2007building} use semi-supervised methods;
%\footnote{This algorithm needs raw data from the target domain, while an annotated general corpus is still used.}; 
Dwinedi and Sukhadeve build a tagger system based only on rules \cite{dwivedi8rule}; while Ruch et al. propose a hybrid system \cite{ruch2000minimal}. Further on, domain adaptation methods (such as EasyAdapt \cite{daume2007frustratingly}, ClinAdapt \cite{ferraro2013improving} 
or reference distribution modelling  \cite{tateisi2006subdomain}) also perform well. However, they need an appropriate amount of manually annotated data from the target domain, which limits their applicability. 

First we examine special properties of clinical notes, then a proper disambiguation methodology is being presented. Our method builds on a trigram tagger and a broad coverage analyzer with an extended lexicon. Further on, our experiments rely on an error analysis of the baseline system (in Section \ref{sec:baseline}), while also incorporate ideas from previous studies.

\subsection{The clinical corpus}

First of all, special properties of clinical texts need to be considered. Such records are created in a special environment, thus they differ from general Hungarian in several aspects. These attributes are the following (cf. \cite{Orosz2013a,Siklosi2013b,Siklosi2012}):
\begin{inparaenum}[\itshape a\upshape)]
 \item notes contain a lot of erroneously spelled words,
 \item sentences generally lack punctuation marks and sentence initial capitalization, 
 \item measurements are frequent and have plenty of different (erroneous) forms,
 \item a lot of (non-standard) abbreviations occur in such texts and
 \item numerous medical terms are used originating from Latin.
\end{inparaenum}

Since there is no corpus of clinical records available being manually annotated with morphological analyses, a new one have been created. This corpus contains about 600 sentences extracted from the notes of 24 different clinics. First, textual parts of the records were identified (as described in \cite{Siklosi2012}), then the paragraphs to be processed were selected randomly. Then, manual sentence boundary segmentation, tokenization and normalization was performed aided by methods detailed in Section \ref{}. 
Manual spelling correction is carried out by using suggestions provided by the system of Siklósi et al. \cite{Siklosi2013}. 
Finally, morphological disambiguation was performed: the initial annotation was provided by PurePos, then its output was checked and corrected manually. 

As regards the morphological annotation of texts, clinical notes differ from general Hungarian. These discrepancies have been considered during its tagging. 
%Beside characteristics described above, the corpus has further specialties. 
First, these texts contain numerous \textit{x} tokens which denote multiplication thus being labeled as numerals. Latin words and abbreviations dominates the sentences, thus they are analyzed regarding their meaning. For example the word \textit{o.} denotes \textit{szem} `eye’, thus it is tagged as a noun with \textsc{n.nom}. Further on, medicine names are also common and being labeled as singular nouns. Finally, numerous sentences lack final punctuation marks which are not recovered in the test corpus, therefore these are not tagged either. 

\begin{table}
\centering
\caption{Size of the clinical corpus created}
\label{tab:clin_corpus}
\begin{tabular}{ l @{\hspace{0.3cm}} r @{\hspace{0.3cm}} r } 
\hline
& Sentences & Tokens \\
\hline
Development set & 240 & 2230 \\
Test set & 333 & 3155 \\
\hline
\end{tabular}
\end{table}

The corpus is split into two sets (cf. Table \ref{tab:clin_corpus}). The first part is employed for development purposes, while new methods are evaluated on the second part.
Precision scores are computed for full analyses of word omitting punctuation marks.

\subsection{The baseline settings}
\label{sec:baseline}

We start our work by creating a baseline tagging chain employing accurate components available for Hungarian. We use Humor, to produce \emph{(morphosyntactic tag, lemma)} pairs as analyses of words, which are then disambiguated by PurePos. However, the output of the MA is extended with the new analyses of \textit{x} in order to fit the corpus to be tagged. 

This baseline text processing chain produced 86.61\% token accuracy on the development set, which is remarkably lower than tagging results for general Hungarian using the same components (96--98\% cf. \ref{}). Measuring precision on sentences revealed that less than the third (28.33\%) of the sentences were tagged correctly. These fact indicates that the models used by the baseline algorithm are weak for such a task. Therefore, errors made by the baseline algorithm are investigated to reveal common pitfalls. 

Table \ref{tab:error_types} shows that the top error class is composed of mistagged abbreviations and acronyms. 
A reason for the high number of such errors is that most of these tokens are unknown to the tagger. 
Moreover, abbreviations usually refer to medical terms originating from Latin.

Another frequent type of mistakes is caused by out-of-vocabulary (OOV) words. These are usually found only in the clinical domain and often originate from Latin.
Although, this observation is in accordance with the PoS tagging results for medical English, listing of such terms' analyses may not be a satisfactory solution to the problem. 
This is because their inflected forms are much more frequent compared to English. 

Finally, domain-specific usage of words leads the tagger astray as well. 
Examples are participles being mislabeled as verbs. 
E.g.\textit{javasolt} `suggested’  and  \textit{felírt} `written’ are common words having different PoS tag distribution in this domain. 
Further on, some erroneous tags are due to the lexical ambiguity being present in Hungarian 
%. Examples are: \textit{lép} that means either `spleen’ (organ) or 
(such as \textit{szembe} which can refer to `into an eye’ or `toward/against’). 

\begin{table}[h]
\centering
\caption{Distribution of errors caused by the baseline algorithm -- dev. set}
\label{tab:error_types}
\begin{tabular}{ l r } 
\hline
Class & Frequency  \\
\hline
Abbreviations and acronyms & 49.17\% \\
Out-of-vocabulary words & 27.27\% \\
Domain-specific PoS of word forms & 14.88\% \\
% Numbers & 0.02\% \\
Other & 0.06\% \\
\hline
\end{tabular}
\end{table}

Our investigation shows that most of the errors of the baseline system can be classified into the three categories shown in Table \ref{tab:error_types}. Admittedly, we utilize this categorization to enhance the baseline method by eliminating its typical errors.

\subsection{Domain adaptation experiments}

Systematic changes are carried out to improve the tagging accuracy of the chain. In doing so, each enhancement is evaluated against the development corpus to measure their usefulness.

\subsubsection{Utilizing an extended morphological lexicon}
\label{sec:ma-extension}

Supervised tagging algorithms commonly use augmented lexicons in order to reduce the number of out-of-vocabulary words (see Section \ref{sec:biomed_tag}). In the case of Hungarian, this must be performed at the level of the MA. This work has been carried out by Novák \cite{} extending the lexicon of Humor with about 40000 entries. For this he used a spelling dictionary of medical terms \cite{Fabian1992} and a freely available list of medicines \cite{Foigazgatosag2012}.

By employing the enhanced lexicon the OOV word ratio is reduced to 26.19\% (from 34.57\%) in development set. Next, the tagger employing the extended analyzer results in an accuracy of 92.41\% (test set). Further on, the medical dictionary \cite{Fabian1992} contained abbreviated words as well, thus this process could decrease the number of mistagged abbreviations.

\subsubsection{Dealing with acronyms and abbreviations}

Despite the changes in Section \ref{sec:ma-extension}, numerous errors made by the improved tagger are still connected to abbreviations. Thus, we first examine erroneous tags of abbreviated terms, then present methods aiming to improve the performance of the disambiguation chain. %TODO: hogy írjuk, hogy HuMor vs. Humor?

A detailed examination revealed that some of the erroneous tags of abbreviated terms are due to the over-generating nature of Humor. 
We reduce such errors applying a simple filtering method. 
An analysis of a word with an attached full stop is considered to be false if the lemma candidate is not an abbreviation. In doing so, the overall accuracy is increased significantly, reducing the number of errors on the development set by 9.20\%.
%(cf. ``Filtering'' in Table \ref{tab:abbrev_fixes}).

Another typical error type is the erroneous tagging of unknown acronyms. Since PurePos do not employ features  dealing with such cases, these tokens are usually left to the suffix guesser resulting in incorrect annotation. However, acronyms should be tagged as singular nouns in most of the cases. Aiming this phenomena, a pattern matching component relying on surface features is employed to fix their tagging.
% (see ``Acronyms'' in Table \ref{tab:abbrev_fixes}). 

Finally, the rest of the errors are mainly connected to those abbreviations which are both unknown to the analyzer and have not been seen previously. For this, the distribution of the labels of abbreviations in the development data is compared to that of the Szeged Corpus (see Table \ref{tab:pos_distribution} below).
While there are several common properties between the two columns (such as the ratio of adverbs), discrepancies are more expressive. The proportion of adjectives is significantly higher in the medical domain than in general Hungarian. Moreover, such differences are more important considering 10.85\% of the tokens are abbreviated in the development set, while the same ratio is only 0.37\% in the Szeged Corpus. 

\begin{table}[h]
\centering
\caption{Morphosyntactic tag frequencies of abbreviations -- dev. set}
\label{tab:pos_distribution}
\begin{tabular}{ l r r} 
\hline
Tag & Clinical texts & Szeged Corpus  \\ 
\hline
\scshape{n.nom} & 67.37\% & 78.18\% \\
\scshape{a.nom} & 19.07\% & 3.96\% \\
\scshape{conj} & 1.27\% & 0.50\% \\
\scshape{adv} & 10.17\% & 11.86\% \\
Other & 2.12\% & 5.50\% \\
\hline
\end{tabular}
\end{table}

Since the noun tag is the most frequent amongst abbreviations, a plausible method (``UnkN'') is to assign \textsc{n.nom} to unknown abbreviations. In doing so, 
%(cf.  ``UnkN'' in Table \ref{tab:abbrev_fixes}) 
we keep the original word forms as lemmata. Although the algorithm is really simple, it results in a surprisingly high error rate reduction of 31.54\%. 

Next, we approximate the analyses of abbreviations with the distribution of tags observed in Table \ref{tab:pos_distribution}. First, we employ (``UnkUni'') a uniform distribution of abbreviations' labels being present in the development.% set as an emission probability distribution. 
In that way, all the tags (\textsc{a.nom}, \textsc{a.pro}, \textsc{adv}, \textsc{conj}, \textsc{n.nom}, \textsc{v.3sg}, \textsc{v.pst\_ptcl}) were used with equal probability as a sort of guessing algorithm.

Beside this, a better method was to use maximum likelihood estimation for calculating a priori probabilities of labels (``UnkMLE''). In this case,  relative frequency estimates are calculated for all the tags enlisted above.
%Evaluation of the methodologies showed (cf. Table \ref{tab:abbrev_fixes}) that 
Investigating the performance of enhancements aiming abbreviations (cf. Table \ref{tab:abbrev_fixes}), we found that the latter approach can increase the overall performance, but ``UnkN'' models the best the task. An explanation for this surprising fact is that the annotated data available can be insufficient for computing the distribution of labels.

\begin{table}[h]
\centering
\caption{Comparison of the techniques aiming to handle acronyms and abbreviations --  dev. set}
\label{tab:abbrev_fixes}
\begin{tabular}{ l l r } 
\hline
ID & Method &  Precision \\
\hline
0 & Medical lexicon & 90.11\% \\
1 & 0 + Filtering & 91.02\% \\
2 & 1 + Acronyms & 91.41\% \\
3 & 2 + UnkN & \underline{94.12\%} \\
4 & 2 + UnkUni & 92.82\% \\
5 & 2 + UnkMLE & 94.01\% \\
\hline
\end{tabular}
\end{table}

\subsubsection{Choosing the proper training data}

Since many studies showed (cf. Section \ref{sec:biomed_tag}) that the training data used significantly affects the result of the annotation chain, we investigated sub-corpora of the training data used. We compared\footnote{Measurements regarding the development set were calculated manually where it was necessary.} several properties of the corpus (cf. Table \ref{tab:subcorpora_attrib}) to find a decent domain fitting best for tagging clinical Hungarian. 

\begin{table}[h]
\centering
\caption{Properties of training corpora}
\label{tab:subcorpora_attrib}
\begin{tabular}{ l r r r r r } 
\hline
\multicolumn{1}{l}{\multirow{2}{*}{Corpus}} & Avg. sent. & Abbrev.  &  Unknown & Perplexity \\
 & length & ratio &  ratio & Words & Tags \\
\hline
Szeged Corpus & 16.82 & 0.37\%\ \ \  & \underline{1.78\%} & \ \ 2318.02 & 22.56\\
\hspace{0.2cm} Fiction & 12.30 & 0.10\% & 2.44\% & 995.57 & 32.57\\
\hspace{0.2cm} Compositions & 13.22 & 0.14\% & 2.29\% & 1335.90 & 30.78\\
\hspace{0.2cm} Computer & 20.75 & 0.14\% & 2.34\% & 854.11 & 22.89\\
\hspace{0.2cm} Newspaper & 21.05 & 0.20\% & 2.10\% & 1284.89 & \underline{22.08}\\
\hspace{0.2cm} Law & 23.64 & 1.43\% & 2.74\% & \underline{824.42} & 29.79\\
\hspace{0.2cm} Short business news & 23.28 & 0.91\% & 2.50\% & 859.33 & 27.88\\
% \hline
Development set & 9.29 & 10.85\% & -- & -- & -- \\
\hline
\end{tabular}
\end{table}

First of all, an important attribute investigated is the length sentences. Texts having shorter sentences tend to have simpler grammatical structure, while longer sentences are grammatically more complex. Further on, clinical texts have a vast amount of abbreviations, thus their ratio is also a relevant metric. 

Furthermore, the accuracy of a tagging system depends heavily on the ratio of unknown words. therefore these proportions are calculated for the development set using the vocabulary of each training corpus (see Table \ref{tab:subcorpora_attrib}). 
%This ratio could function as a similarity metric, but entropy-based measures work better  in such scenarios. 
Besides, we also sue perplexity, since it can be used to measure similarity of corpora \cite{kilgarriff1998measures}. 
Calculation is carried out as follows: trigram models of word and tag sequences are trained on each corpus using Kneser-Ney smoothing, then all of them are evaluated against the development set\footnote{We used the SRILM toolkit \cite{stolcke2002srilm} for training models and measuring perplexity.}.

Similarity scores show that there parts of the Szeged Corpus do not have as much abbreviated terms as clinical texts have. 
Likewise, sentences written by clinicians are significantly shorter than ones in the Szeged Corpus. 
Neither the calculations above, nor the ratio of unknown words suggest using subcorpora for training. However, the perplexity scores contradict: sentences from the law domain have the most phrases in common with clinical notes, while news texts have the most similar grammatical structures. 

Therefore, all sub-corpora are tested as a training data for tagging the development set. In doing so, we used the previously improved tagger (cf. Section \ref{}). Results in Table  \ref{tab:eval_subcorpora} show that training on news texts results in high accuracy, however the whole data yields better tagger.

\begin{table}
\centering
\caption{Evaluation of the tagger using the subcorpora as training data -- dev. set}
\label{tab:eval_subcorpora}
\begin{tabular}{ l r } 
\hline
Corpus & Morph. disambiguation accuracy \\
\hline
Szeged Corpus & \underline{94.73\%} \\
\hspace{0.2cm} Fiction & 92.01\% \\
\hspace{0.2cm} Compositions & 91.97\% \\
\hspace{0.2cm} Computer & 92.73\% \\
\hspace{0.2cm} Newspaper & \underline{93.29\%} \\
\hspace{0.2cm} Law & 92.17\% \\
\hspace{0.2cm} Short business news & 92.69\% \\
\hline
\end{tabular}
\end{table}


\subsection{Evaluation}

We evaluate our improved tagging chain (cf. Table \ref{tab:improvements}) by investigating contains the part-of-speech tagging, lemmatization and the whole morphological tagging performance of each enhancement performed.



\begin{table}[h]
\centering
\caption{Evaluation of the improved tagger -- test set}
\label{tab:improvements}
\begin{tabular}{ l l r r r} 
\hline
ID & Method & PoS tagging & Lemmatization & Morph. disambig. \\
\hline
0 & Baseline system & 90.57\% & 93.54\% & 88.09\% \\
1 & 0 + Lexicon extension & 93.89\% & 96.24\% & 92.41\% \\
2 & 1 + Handling abbreviations & \underline{94.81\%} & \underline{97.60\%} & \underline{93.73\%} \\
3 & 2 + Training data selection & 94.25\% & 97.36\% & 93.29\% \\
\hline
\end{tabular}
\end{table}

Our enhancements raised the ceiling of the full morphological tagging accuracy to 93.73\% by eliminating almost half (47.36\%) of the errors. 
As results indicate  error rate reduction is due to the usage of the extended lexicon, which significantly decreased the number of the out-of-vocabulary tokens. 
Further on, we showed the using a uniform distribution for handling abbreviations improves the tagger used.
While this research did not manage to find decent training data for tagging clinical Hungarian, it showed that neither part of the Szeged Corpus was able to outperform the whole as a training corpus. 

In sum, commonly used methodologies alone fail to tag Hungarian clinical texts with a satisfactory accuracy. One of the main problems is that such algorithms are not able to deal with the tagging of abbreviations. However, methods presented yields a tagger which is a good base for annotation scenarios.

%TODO az elejéről ide kellene hozni a táblázatot + néhány sor + konklúzió
% 
% In this study, resources and methodologies were introduced that enabled us to investigate morphological tagging of clinical Hungarian. First, a test corpus was created and was compared in detail with a general Hungarian corpus. This corpus also allowed for the evaluation of numerous tagging approaches. These experiments were based on the PurePos tagger tool and the HuMor morphological analyzer. Errors made by the baseline morphological disambiguation chain were investigated, then several enhancements were carried out aiming at correcting the most common mistakes of the baseline algorithm. Amongst others, we extended the lexicon of the morphological analyzer and introduced several methods to handle the errors caused by abbreviations. 
% 
% The baseline setup labeled every eighth token erroneously. Although this tagging chain is commonly used for parsing general Hungarian, it resulted in mistagged medical sentences in two thirds of the cases. In contrast,
% our enhancements raised the ceiling of the tagging accuracy to 93.73\% by eliminating almost half (47.36\%) of the mistakes. Deeper investigation revealed that this error rate reduction was mainly due to the usage of the extended lexicon, which significantly decreased the number of the out-of-vocabulary tokens. While this research did not manage to find decent training data for tagging clinical Hungarian, it showed that neither part of the Szeged Corpus was able to outperform the whole as a training corpus. Finally, results of tagging abbreviations suggest that abbreviated terms should not be tagged directly. They should be resolved first or should be labeled with a uniform tag.% The latter approach would let further practical applications to handle them. 

% The main limitation of this research is the corpus used. It contains a few hundred sentences, which is only enough to reveal the main pitfalls of the tagging method. Furthermore, most of the domain adaptation methods rely on target-specific corpora that have several thousands of sentences. Taking these into consideration, further investigation should involve more manually annotated data from the medical domain. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 
